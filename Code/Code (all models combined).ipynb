{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sbn\n",
    "import datetime\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>gasoline</th>\n",
       "      <th>crude_futures</th>\n",
       "      <th>gdp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-Jan-01</td>\n",
       "      <td>1.406</td>\n",
       "      <td>27.95</td>\n",
       "      <td>12999.56990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8-Jan-01</td>\n",
       "      <td>1.425</td>\n",
       "      <td>30.05</td>\n",
       "      <td>12293.34053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15-Jan-01</td>\n",
       "      <td>1.474</td>\n",
       "      <td>32.19</td>\n",
       "      <td>12708.81038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22-Jan-01</td>\n",
       "      <td>1.471</td>\n",
       "      <td>29.77</td>\n",
       "      <td>12287.22655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29-Jan-01</td>\n",
       "      <td>1.460</td>\n",
       "      <td>31.19</td>\n",
       "      <td>13353.26284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>24-Nov-08</td>\n",
       "      <td>1.892</td>\n",
       "      <td>54.43</td>\n",
       "      <td>15451.90316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1-Dec-08</td>\n",
       "      <td>1.811</td>\n",
       "      <td>40.81</td>\n",
       "      <td>15362.37041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>8-Dec-08</td>\n",
       "      <td>1.699</td>\n",
       "      <td>46.28</td>\n",
       "      <td>14770.91456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>15-Dec-08</td>\n",
       "      <td>1.659</td>\n",
       "      <td>33.87</td>\n",
       "      <td>15966.69919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>22-Dec-08</td>\n",
       "      <td>1.653</td>\n",
       "      <td>37.71</td>\n",
       "      <td>15333.04947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>417 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  gasoline  crude_futures          gdp\n",
       "0     1-Jan-01     1.406          27.95  12999.56990\n",
       "1     8-Jan-01     1.425          30.05  12293.34053\n",
       "2    15-Jan-01     1.474          32.19  12708.81038\n",
       "3    22-Jan-01     1.471          29.77  12287.22655\n",
       "4    29-Jan-01     1.460          31.19  13353.26284\n",
       "..         ...       ...            ...          ...\n",
       "412  24-Nov-08     1.892          54.43  15451.90316\n",
       "413   1-Dec-08     1.811          40.81  15362.37041\n",
       "414   8-Dec-08     1.699          46.28  14770.91456\n",
       "415  15-Dec-08     1.659          33.87  15966.69919\n",
       "416  22-Dec-08     1.653          37.71  15333.04947\n",
       "\n",
       "[417 rows x 4 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data TODO: 改成data importer\n",
    "df = pd.read_csv('..\\\\Data\\\\cleansed_data\\\\test.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating independent and dependent variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>gasoline</th>\n",
       "      <th>crude_futures</th>\n",
       "      <th>gdp</th>\n",
       "      <th>of_chg_1</th>\n",
       "      <th>of_chg_2</th>\n",
       "      <th>of_chg_3</th>\n",
       "      <th>of_chg_5</th>\n",
       "      <th>of_chg_10</th>\n",
       "      <th>gas_chg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>19-Mar-01</td>\n",
       "      <td>1.404</td>\n",
       "      <td>27.30</td>\n",
       "      <td>11982.22891</td>\n",
       "      <td>0.020942</td>\n",
       "      <td>-0.025348</td>\n",
       "      <td>-0.019397</td>\n",
       "      <td>-0.063786</td>\n",
       "      <td>-0.091514</td>\n",
       "      <td>-0.005666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>26-Mar-01</td>\n",
       "      <td>1.404</td>\n",
       "      <td>26.29</td>\n",
       "      <td>13936.69786</td>\n",
       "      <td>-0.036996</td>\n",
       "      <td>-0.016829</td>\n",
       "      <td>-0.061407</td>\n",
       "      <td>-0.094697</td>\n",
       "      <td>-0.183287</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2-Apr-01</td>\n",
       "      <td>1.442</td>\n",
       "      <td>27.06</td>\n",
       "      <td>12809.32454</td>\n",
       "      <td>0.029289</td>\n",
       "      <td>-0.008791</td>\n",
       "      <td>0.011967</td>\n",
       "      <td>-0.028017</td>\n",
       "      <td>-0.091031</td>\n",
       "      <td>0.027066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9-Apr-01</td>\n",
       "      <td>1.500</td>\n",
       "      <td>28.25</td>\n",
       "      <td>13474.20064</td>\n",
       "      <td>0.043976</td>\n",
       "      <td>0.074553</td>\n",
       "      <td>0.034799</td>\n",
       "      <td>0.008568</td>\n",
       "      <td>-0.094261</td>\n",
       "      <td>0.040222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16-Apr-01</td>\n",
       "      <td>1.571</td>\n",
       "      <td>27.28</td>\n",
       "      <td>13236.22196</td>\n",
       "      <td>-0.034336</td>\n",
       "      <td>0.008130</td>\n",
       "      <td>0.037657</td>\n",
       "      <td>0.020194</td>\n",
       "      <td>-0.120851</td>\n",
       "      <td>0.047333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>24-Nov-08</td>\n",
       "      <td>1.892</td>\n",
       "      <td>54.43</td>\n",
       "      <td>15451.90316</td>\n",
       "      <td>0.090126</td>\n",
       "      <td>-0.045757</td>\n",
       "      <td>-0.108290</td>\n",
       "      <td>-0.151520</td>\n",
       "      <td>-0.479388</td>\n",
       "      <td>-0.086873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1-Dec-08</td>\n",
       "      <td>1.811</td>\n",
       "      <td>40.81</td>\n",
       "      <td>15362.37041</td>\n",
       "      <td>-0.250230</td>\n",
       "      <td>-0.182656</td>\n",
       "      <td>-0.284537</td>\n",
       "      <td>-0.398171</td>\n",
       "      <td>-0.618206</td>\n",
       "      <td>-0.042812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>8-Dec-08</td>\n",
       "      <td>1.699</td>\n",
       "      <td>46.28</td>\n",
       "      <td>14770.91456</td>\n",
       "      <td>0.134036</td>\n",
       "      <td>-0.149734</td>\n",
       "      <td>-0.073102</td>\n",
       "      <td>-0.241809</td>\n",
       "      <td>-0.507030</td>\n",
       "      <td>-0.061844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>15-Dec-08</td>\n",
       "      <td>1.659</td>\n",
       "      <td>33.87</td>\n",
       "      <td>15966.69919</td>\n",
       "      <td>-0.268150</td>\n",
       "      <td>-0.170056</td>\n",
       "      <td>-0.377733</td>\n",
       "      <td>-0.406206</td>\n",
       "      <td>-0.564093</td>\n",
       "      <td>-0.023543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>22-Dec-08</td>\n",
       "      <td>1.653</td>\n",
       "      <td>37.71</td>\n",
       "      <td>15333.04947</td>\n",
       "      <td>0.113375</td>\n",
       "      <td>-0.185177</td>\n",
       "      <td>-0.075962</td>\n",
       "      <td>-0.244743</td>\n",
       "      <td>-0.475157</td>\n",
       "      <td>-0.003617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>406 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  gasoline  crude_futures          gdp  of_chg_1  of_chg_2  \\\n",
       "11   19-Mar-01     1.404          27.30  11982.22891  0.020942 -0.025348   \n",
       "12   26-Mar-01     1.404          26.29  13936.69786 -0.036996 -0.016829   \n",
       "13    2-Apr-01     1.442          27.06  12809.32454  0.029289 -0.008791   \n",
       "14    9-Apr-01     1.500          28.25  13474.20064  0.043976  0.074553   \n",
       "15   16-Apr-01     1.571          27.28  13236.22196 -0.034336  0.008130   \n",
       "..         ...       ...            ...          ...       ...       ...   \n",
       "412  24-Nov-08     1.892          54.43  15451.90316  0.090126 -0.045757   \n",
       "413   1-Dec-08     1.811          40.81  15362.37041 -0.250230 -0.182656   \n",
       "414   8-Dec-08     1.699          46.28  14770.91456  0.134036 -0.149734   \n",
       "415  15-Dec-08     1.659          33.87  15966.69919 -0.268150 -0.170056   \n",
       "416  22-Dec-08     1.653          37.71  15333.04947  0.113375 -0.185177   \n",
       "\n",
       "     of_chg_3  of_chg_5  of_chg_10   gas_chg  \n",
       "11  -0.019397 -0.063786  -0.091514 -0.005666  \n",
       "12  -0.061407 -0.094697  -0.183287  0.000000  \n",
       "13   0.011967 -0.028017  -0.091031  0.027066  \n",
       "14   0.034799  0.008568  -0.094261  0.040222  \n",
       "15   0.037657  0.020194  -0.120851  0.047333  \n",
       "..        ...       ...        ...       ...  \n",
       "412 -0.108290 -0.151520  -0.479388 -0.086873  \n",
       "413 -0.284537 -0.398171  -0.618206 -0.042812  \n",
       "414 -0.073102 -0.241809  -0.507030 -0.061844  \n",
       "415 -0.377733 -0.406206  -0.564093 -0.023543  \n",
       "416 -0.075962 -0.244743  -0.475157 -0.003617  \n",
       "\n",
       "[406 rows x 10 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate independent variables\n",
    "periods = (1,2,3,5,10)\n",
    "for i in periods:\n",
    "    df['of_chg_{}'.format(i)] = df['crude_futures'].pct_change(periods = i)\n",
    "    \n",
    "# calculate dependent variable\n",
    "df['gas_chg'] = df['gasoline'].pct_change()\n",
    "\n",
    "# eliminate the empty rows\n",
    "df = df[11:]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seperating training, validation, and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.73000000e+01,  2.09424084e-02, -2.53480900e-02, ...,\n",
       "        -6.37860082e-02, -9.15141431e-02,  1.19822289e+04],\n",
       "       [ 2.62900000e+01, -3.69963370e-02, -1.68287210e-02, ...,\n",
       "        -9.46969697e-02, -1.83286735e-01,  1.39366979e+04],\n",
       "       [ 2.70600000e+01,  2.92887029e-02, -8.79120879e-03, ...,\n",
       "        -2.80172414e-02, -9.10312395e-02,  1.28093245e+04],\n",
       "       ...,\n",
       "       [ 4.62800000e+01,  1.34035776e-01, -1.49733603e-01, ...,\n",
       "        -2.41808650e-01, -5.07030251e-01,  1.47709146e+04],\n",
       "       [ 3.38700000e+01, -2.68150389e-01, -1.70056359e-01, ...,\n",
       "        -4.06206171e-01, -5.64092664e-01,  1.59666992e+04],\n",
       "       [ 3.77100000e+01,  1.13374668e-01, -1.85177182e-01, ...,\n",
       "        -2.44742640e-01, -4.75156576e-01,  1.53330495e+04]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create list of independent variable's name\n",
    "ind_var_name = ['of_chg_{}'.format(i) for i in periods]+['gdp']\n",
    "\n",
    "# extract the values to X\n",
    "X = df[['crude_futures'] + ind_var_name].values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((406, 7), (406,))"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create y\n",
    "y = (df['gas_chg'] > 0).values.astype('int')\n",
    "\n",
    "# check correctness of X and y\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:\t (284, 7)\n",
      "X_test shape:\t (61, 7)\n",
      "X_val shape:\t (61, 7)\n",
      "y_train shape:\t (284,)\n",
      "y_val shape:\t (61,)\n",
      "y_test shape:\t (61,)\n"
     ]
    }
   ],
   "source": [
    "# create training, validation, and test sets\n",
    "training_ratio = 0.7\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_ratio, random_state = 42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = validation_ratio/(validation_ratio + training_ratio), random_state = 42)\n",
    "\n",
    "\n",
    "print(\"X_train shape:\\t\", X_train.shape)\n",
    "print(\"X_test shape:\\t\", X_test.shape)\n",
    "print(\"X_val shape:\\t\", X_val.shape)\n",
    "print(\"y_train shape:\\t\", y_train.shape)\n",
    "print(\"y_val shape:\\t\", y_val.shape)\n",
    "print(\"y_test shape:\\t\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:\t (284, 7)\n",
      "X_val shape:\t (61, 7)\n"
     ]
    }
   ],
   "source": [
    "# normalization \n",
    "for i in range(X_train.shape[1]):\n",
    "    X_train_mean = X_train[:, i]. mean()\n",
    "    X_train_std = X_train[:, i].std()\n",
    "    X_train[:, i] = (X_train[:,i] - X_train_mean) / X_train_std\n",
    "    X_test[:,i] = (X_test[:,i] - X_train_mean) / X_train_std\n",
    "    X_val[:, i] = (X_val[:,i] - X_train_mean) / X_train_std\n",
    "\n",
    "print(\"X_train shape:\\t\", X_train.shape)\n",
    "print(\"X_val shape:\\t\", X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:\t (284, 6)\n",
      "X_test shape:\t (61, 6)\n",
      "X_val shape:\t (61, 6)\n",
      "y_train shape:\t (284,)\n",
      "y_val shape:\t (61,)\n",
      "y_test shape:\t (61,)\n"
     ]
    }
   ],
   "source": [
    "# fit on training set\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# apply transform to training and test set\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "# set PCA value\n",
    "pca = PCA(0.95)\n",
    "\n",
    "# fit PCA training set\n",
    "pca.fit(X_train)\n",
    "\n",
    "# apply transform to training and test set\n",
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "X_val = pca.transform(X_val)\n",
    "print(\"X_train shape:\\t\", X_train.shape)\n",
    "print(\"X_test shape:\\t\", X_test.shape)\n",
    "print(\"X_val shape:\\t\", X_val.shape)\n",
    "print(\"y_train shape:\\t\", y_train.shape)\n",
    "print(\"y_val shape:\\t\", y_val.shape)\n",
    "print(\"y_test shape:\\t\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_clf: 0.6885\n",
      "score_clf: 0.6721\n",
      "score_clf: 0.6885\n",
      "score_clf: 0.6721\n",
      "score_clf: 0.6885\n",
      "score_clf: 0.7213\n",
      "score_clf: 0.7049\n",
      "score_clf: 0.7377\n",
      "score_clf: 0.7049\n",
      "score_clf: 0.7377\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "# TODO: 这里我写的range（1,11）但是我不知道11是哪里来的\n",
    "for i in range (1, 11):\n",
    "    clf = RandomForestClassifier(max_depth=i, random_state=0).fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_val)\n",
    "    score_clf = accuracy_score(y_val, y_pred)\n",
    "    print('score_clf:', \"%.4f\"%score_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_clf: 0.7541\n"
     ]
    }
   ],
   "source": [
    "# choose max_depth = 4\n",
    "clf = RandomForestClassifier(max_depth=4, random_state=0).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "score_clf = accuracy_score(y_test, y_pred)\n",
    "print('score_clf:', \"%.4f\"%score_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_logistic: 0.7705\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_model = LogisticRegression(penalty = 'l1', solver='liblinear', random_state=0).fit(X_train, y_train)\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "score_logistic = accuracy_score(y_test, y_pred)\n",
    "print('score_logistic:', \"%.4f\"%score_logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_orig shape:\t (284, 7)\n",
      "X_test_orig shape:\t (61, 7)\n",
      "X_val_orig shape:\t (61, 7)\n",
      "y_train_orig shape:\t (284,)\n",
      "y_val_orig shape:\t (61,)\n",
      "y_test_orig shape:\t (61,)\n"
     ]
    }
   ],
   "source": [
    "# regression cases\n",
    "y_orig = df['gas_chg']\n",
    "X_train_orig, X_test_orig, y_train_orig, y_test_orig = train_test_split(X, y_orig, test_size = test_ratio, random_state = 42)\n",
    "X_train_orig, X_val_orig, y_train_orig, y_val_orig = train_test_split(X_train_orig, y_train_orig, test_size = validation_ratio/(validation_ratio + training_ratio), random_state = 42)\n",
    "print(\"X_train_orig shape:\\t\", X_train_orig.shape)\n",
    "print(\"X_test_orig shape:\\t\", X_test_orig.shape)\n",
    "print(\"X_val_orig shape:\\t\", X_val_orig.shape)\n",
    "print(\"y_train_orig shape:\\t\", y_train_orig.shape)\n",
    "print(\"y_val_orig shape:\\t\", y_val_orig.shape)\n",
    "print(\"y_test_orig shape:\\t\", y_test_orig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:\t (284, 6)\n",
      "X_val shape:\t (61, 6)\n"
     ]
    }
   ],
   "source": [
    "# TODO: 这个地方PCA怎么弄还是不弄？\n",
    "# normalization for regressor\n",
    "for i in range(X_train_orig.shape[1]):\n",
    "    X_train_orig_mean = X_train_orig[:, i]. mean()\n",
    "    X_train_orig_std = X_train_orig[:, i].std()\n",
    "    X_train_orig[:, i] = (X_train_orig[:,i] - X_train_orig_mean) / X_train_orig_std\n",
    "    X_test_orig[:,i] = (X_test_orig[:,i] - X_train_orig_mean) / X_train_orig_std\n",
    "    X_val_orig[:, i] = (X_val_orig[:,i] - X_train_orig_mean) / X_train_orig_std\n",
    "\n",
    "print(\"X_train shape:\\t\", X_train.shape)\n",
    "print(\"X_val shape:\\t\", X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_multiple_reg: 0.4886\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "multiple_reg = LinearRegression().fit(X_train_orig, y_train_orig)\n",
    "# y_pred = multiple_reg.predict(X_test_orig)\n",
    "score_multiple_reg = multiple_reg.score(X_test_orig, y_test_orig)\n",
    "print('score_multiple_reg:', \"%.4f\"%score_multiple_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_clf_reg: 0.4118\n"
     ]
    }
   ],
   "source": [
    "clf_reg = RandomForestRegressor().fit(X_train_orig, y_train_orig)\n",
    "y_pred = clf_reg.predict(X_test_orig)\n",
    "score_clf_reg = clf_reg.score(X_test_orig, y_test_orig)\n",
    "print('score_clf_reg:', \"%.4f\"%score_clf_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-17856.07324108401"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: 这个score不太对劲\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "degree=5\n",
    "# polyreg=make_pipeline(PolynomialFeatures(degree),LinearRegression())\n",
    "poly = PolynomialFeatures(degree)\n",
    "X_ = poly.fit_transform(X_train_orig)\n",
    "X_val = poly.fit_transform(X_val_orig)\n",
    "polyreg = LinearRegression().fit(X_, y_train_orig)\n",
    "poly_reg_score = polyreg.score(X_val, y_val_orig)\n",
    "poly_reg_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient boosting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7213114754098361"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gra_clf = GradientBoostingClassifier(n_estimators = 200, learning_rate=0.50, max_depth=5, random_state=0).fit(X_train, y_train)\n",
    "gra_clf_score = gra_clf.score(X_test, y_test)\n",
    "gra_clf_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient boosting regressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32641094272503834"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gra_reg = GradientBoostingRegressor(random_state=0)\n",
    "gra_reg.fit(X_train_orig, y_train_orig)\n",
    "GradientBoostingRegressor(random_state=0)\n",
    "gra_reg_score = gra_reg.score(X_test_orig, y_test_orig)\n",
    "gra_reg_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support vector classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7213114754098361\n",
      "0.6557377049180327\n",
      "0.6721311475409836\n"
     ]
    }
   ],
   "source": [
    "# Try different kernels\n",
    "kernels = ('linear', 'poly', 'rbf')\n",
    "\n",
    "\n",
    "for k in kernels:\n",
    "    svm_clf = SVC(kernel=k).fit(X_train, y_train)\n",
    "    y_pred = svm_clf.predict(X_test)\n",
    "    vars()[f'score_svc_{k}']= accuracy_score(y_test, y_pred)\n",
    "    \n",
    "print(score_svc_linear)\n",
    "print(score_svc_poly)\n",
    "print(score_svc_rbf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7049180327868853\n"
     ]
    }
   ],
   "source": [
    "gnb_clf = GaussianNB().fit(X_train, y_train)\n",
    "y_pred = gnb_clf.predict(X_test)\n",
    "gnb_score = accuracy_score(y_test, y_pred)\n",
    "print(gnb_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuro networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/9 [==>...........................] - ETA: 2s - loss: 0.6108 - accuracy: 0.6562"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1233 test_function  *\n        return step_function(self, iterator)\n    C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1224 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1217 run_step  **\n        outputs = model.test_step(data)\n    C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1183 test_step\n        y_pred = self(x, training=False)\n    C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:255 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential_6 is incompatible with the layer: expected axis -1 of input shape to have value 6 but received input with shape (None, 792)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-151-354aa877a0f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1129\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[1;32m-> 1131\u001b[1;33m           val_logs = self.evaluate(\n\u001b[0m\u001b[0;32m   1132\u001b[0m               \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1133\u001b[0m               \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[0;32m   1387\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1389\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1390\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    869\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    872\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    723\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 725\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    726\u001b[0m             *args, **kwds))\n\u001b[0;32m    727\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2968\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2969\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2970\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2971\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3196\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 990\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    975\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    976\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 977\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    978\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    979\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1233 test_function  *\n        return step_function(self, iterator)\n    C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1224 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1217 run_step  **\n        outputs = model.test_step(data)\n    C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1183 test_step\n        y_pred = self(x, training=False)\n    C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:255 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential_6 is incompatible with the layer: expected axis -1 of input shape to have value 6 but received input with shape (None, 792)\n"
     ]
    }
   ],
   "source": [
    "#TODO: 看不懂是什么问题，好像是dataset的大小不对，但是我不明白\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(10, input_dim=6, activation='relu'))\n",
    "model.add(keras.layers.Dense(5, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6747 - accuracy: 0.5246\n",
      "0.5245901346206665\n"
     ]
    }
   ],
   "source": [
    "loss, neuro_score = model.evaluate(X_test, y_test)\n",
    "print(neuro_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multiple linear regression</td>\n",
       "      <td>0.488581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Multiple polynomial regression</td>\n",
       "      <td>-17856.073241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic regression</td>\n",
       "      <td>0.754098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random forest classifier</td>\n",
       "      <td>0.786885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random forest regressor</td>\n",
       "      <td>0.393384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gradient boosting classifier</td>\n",
       "      <td>0.326411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gradient boosting regressor</td>\n",
       "      <td>0.721311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gaussian naive Bayes</td>\n",
       "      <td>0.704918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVC linear</td>\n",
       "      <td>0.721311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVC polynomial</td>\n",
       "      <td>0.639344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVC RBF</td>\n",
       "      <td>0.737705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Neuro network</td>\n",
       "      <td>0.524590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model         Score\n",
       "0       Multiple linear regression      0.488581\n",
       "1   Multiple polynomial regression -17856.073241\n",
       "2              Logistic regression      0.754098\n",
       "3         Random forest classifier      0.786885\n",
       "4          Random forest regressor      0.393384\n",
       "5     Gradient boosting classifier      0.326411\n",
       "6      Gradient boosting regressor      0.721311\n",
       "7             Gaussian naive Bayes      0.704918\n",
       "8                       SVC linear      0.721311\n",
       "9                   SVC polynomial      0.639344\n",
       "10                         SVC RBF      0.737705\n",
       "11                   Neuro network      0.524590"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = [score_multiple_reg, poly_reg_score, score_logistic, score_clf, score_clf_reg, gra_reg_score, gra_clf_score,gnb_score, score_svc_linear, score_svc_poly, score_svc_rbf, neuro_score]\n",
    "models = ['Multiple linear regression', 'Multiple polynomial regression', 'Logistic regression', 'Random forest classifier', 'Random forest regressor', 'Gradient boosting classifier', 'Gradient boosting regressor','Gaussian naive Bayes', 'SVC linear', 'SVC polynomial', 'SVC RBF', 'Neuro network']\n",
    "result = pd.DataFrame(columns = ['Model','Score'])\n",
    "result['Model'] = models\n",
    "result['Score'] = scores\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
