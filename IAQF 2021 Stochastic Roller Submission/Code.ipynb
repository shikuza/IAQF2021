{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IAQF 2021 Code Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROBLEM_NO = 1\n",
    "PERIOD_NO = 'basic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sbn\n",
    "\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingClassifier,GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OS = 'Mac'  # OS is either 'Mac' or 'Windows'\n",
    "sep = '/' if OS == 'Mac' else '\\\\'\n",
    "path = \"source_data{}{}.csv\"\n",
    "\n",
    "PROBLEM_PATH_DICT = {\n",
    "    1: {\n",
    "        'basic': path.format(sep, \"crude_gas_et_df\"),\n",
    "        'et': path.format(sep, \"crude_gas_et_df\"),\n",
    "        'p1': path.format(sep, \"crude_gas_p1_df\"),\n",
    "        'p1.2': path.format(sep, \"crude_gas_p2_df\"),\n",
    "        'p2': path.format(sep, \"crude_gas_p2_df\")\n",
    "    },  # crude oil price vs. gasoline price\n",
    "    2: {\n",
    "        'basic': path.format(sep, \"cf_gas_et_df\"),\n",
    "        'et': path.format(sep, \"cf_gas_et_df\"),\n",
    "        'p1': path.format(sep, \"cf_gas_p1_df\"),\n",
    "        'p1.2': path.format(sep, \"cf_gas_p2_df\"),\n",
    "        'p2': path.format(sep, \"cf_gas_p2_df\"),\n",
    "    },  # crude oil futures price vs. gasoline price\n",
    "    3: {\n",
    "        'basic': path.format(sep, \"crude_co2_et_df\"),\n",
    "        'et': path.format(sep, \"crude_co2_et_df\"),\n",
    "        'p1': path.format(sep, \"crude_co2_p1_df\"),\n",
    "        'p1.2': path.format(sep, \"crude_co2_p2_df\"),\n",
    "        'p2': path.format(sep, \"crude_co2_p2_df\")\n",
    "    }  # crude oil price vs. co2\n",
    "}\n",
    "\n",
    "PROBLEM_VAR_DICT = {\n",
    "    1: ('crude_oil', 'gasoline'),\n",
    "    2: ('oil_futures', 'gasoline'),\n",
    "    3: ('crude_oil', 'co2')\n",
    "}\n",
    "\n",
    "ADDITIONAL_VAR_DICT = {\n",
    "    1: {\n",
    "        'basic': [],\n",
    "        'et': ['cpi','us_pop','public_roads','us_urban_pop','oil_production','auto_sales','us_real_gdp'],\n",
    "        'p1': ['cpi','us_pop','public_roads','us_urban_pop','oil_production','auto_sales','us_real_gdp'],\n",
    "        'p1.2': ['cpi','us_pop','public_roads','us_urban_pop','oil_production','auto_sales','us_real_gdp'],\n",
    "        'p2': ['cpi','us_pop','public_roads','us_urban_pop','oil_production','djus_auto_index','auto_sales','us_real_gdp','usd_mex_exrate']\n",
    "        \n",
    "    },\n",
    "    2: {\n",
    "        'basic': [],\n",
    "        'et': ['cpi','us_pop','public_roads','us_urban_pop','oil_production','auto_sales','us_real_gdp'],\n",
    "        'p1': ['cpi','us_pop','public_roads','us_urban_pop','oil_production','auto_sales','us_real_gdp'],\n",
    "        'p1.2': ['cpi','us_pop','public_roads','us_urban_pop','oil_production','auto_sales','us_real_gdp'],\n",
    "        'p2': ['cpi','us_pop','public_roads','us_urban_pop','oil_production','djus_auto_index','auto_sales','us_real_gdp','usd_mex_exrate']\n",
    "\n",
    "    },\n",
    "    3: {\n",
    "        'basic': [],\n",
    "        'et': ['cpi','coal_consumption','ngas_consumption','us_pop','oil_production','tree_cover_loss','us_real_gdp'],\n",
    "        'p1': ['cpi','coal_consumption','ngas_consumption','us_pop','oil_production','tree_cover_loss','us_real_gdp'],\n",
    "        'p1.2': ['cpi','coal_consumption','ngas_consumption','us_pop','oil_production','tree_cover_loss','us_real_gdp'],\n",
    "        'p2': ['cpi','coal_consumption','ngas_consumption','us_pop','oil_production','cattle_index','tree_cover_loss','us_real_gdp','usd_mex_exrate']\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sheetname = str(PROBLEM_NO) + PERIOD_NO\n",
    "\n",
    "X_MAIN_COL, Y_COL = PROBLEM_VAR_DICT[PROBLEM_NO]\n",
    "X_MAIN_CHG_COL = X_MAIN_COL + '_chg'\n",
    "Y_CHG_COL = Y_COL + '_chg'\n",
    "EXTRA_VARS = ADDITIONAL_VAR_DICT[PROBLEM_NO][PERIOD_NO]\n",
    "\n",
    "TRAINING_RATIO_DEFAULT = 0.7\n",
    "VALIDATION_RATIO_DEFAULT = 0.15\n",
    "TEST_RATIO_DEFAULT = 0.15\n",
    "\n",
    "REGRESSOR_ACCURACY_DICT = {}\n",
    "CLASSIFIER_ACCURACY_DICT = {}\n",
    "\n",
    "REGRESSOR_COEF_DICT = {}\n",
    "CLASSIFIER_COEF_DICT = {}\n",
    "\n",
    "df = pd.read_csv(PROBLEM_PATH_DICT[PROBLEM_NO][PERIOD_NO])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating independent and dependent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate independent variables\n",
    "periods = (1,2,3,5,10)\n",
    "for i in periods:\n",
    "    df [X_MAIN_CHG_COL + f'_{i}'] = df[X_MAIN_COL].pct_change(periods=i)\n",
    "\n",
    "# calculate dependent variable\n",
    "df[Y_CHG_COL] = df[Y_COL].pct_change(periods=1)\n",
    "\n",
    "# eliminate the empty rows\n",
    "df = df[11:]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seperating training, validation, and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of independent variable's name\n",
    "indep_vars = [X_MAIN_CHG_COL + f'_{i}' for i in periods] + EXTRA_VARS\n",
    "num_var =len(indep_vars)\n",
    "\n",
    "# extract the values to X\n",
    "X = df[[X_MAIN_COL] + indep_vars].values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create y for regressor, y_c for classifier\n",
    "y = df[Y_CHG_COL]\n",
    "y_c = (df[Y_CHG_COL] > 0).values.astype('int')\n",
    "\n",
    "# set training, validation, and test criterias\n",
    "training_ratio = TRAINING_RATIO_DEFAULT\n",
    "validation_ratio = VALIDATION_RATIO_DEFAULT\n",
    "test_ratio = TEST_RATIO_DEFAULT\n",
    "\n",
    "# check correctness of X and y\n",
    "X.shape, y.shape, y_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training, validation, and test sets for regressor\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_ratio, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=validation_ratio/(validation_ratio+training_ratio), random_state=42)\n",
    "\n",
    "print(\"X_train shape:\\t\", X_train.shape)\n",
    "print(\"X_test shape:\\t\", X_test.shape)\n",
    "print(\"X_val shape:\\t\", X_val.shape)\n",
    "print(\"y_train shape:\\t\", y_train.shape)\n",
    "print(\"y_val shape:\\t\", y_val.shape)\n",
    "print(\"y_test shape:\\t\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training, validation, and test sets for classifier\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X, y_c, test_size=test_ratio, random_state=42)\n",
    "X_train_c, X_val_c, y_train_c, y_val_c = train_test_split(X_train_c, y_train_c, test_size=validation_ratio/(validation_ratio+training_ratio), random_state=42)\n",
    "\n",
    "print(\"X_train_c shape:\", X_train_c.shape)\n",
    "print(\"X_test_c shape:\\t\", X_test_c.shape)\n",
    "print(\"X_val_c shape:\\t\", X_val_c.shape)\n",
    "print(\"y_train_c shape:\", y_train_c.shape)\n",
    "print(\"y_val_c shape:\\t\", y_val_c.shape)\n",
    "print(\"y_test_c shape:\\t\", y_test_c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization for regressor set\n",
    "for i in range(X_train.shape[1]):\n",
    "    X_train_mean = X_train[:, i]. mean()\n",
    "    X_train_std = X_train[:, i].std()\n",
    "    X_train[:, i] = (X_train[:,i] - X_train_mean) / X_train_std\n",
    "    X_test[:,i] = (X_test[:,i] - X_train_mean) / X_train_std\n",
    "    X_val[:, i] = (X_val[:,i] - X_train_mean) / X_train_std\n",
    "\n",
    "print(\"X_train shape:\\t\", X_train.shape)\n",
    "print(\"X_val shape:\\t\", X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization for classifier set\n",
    "for i in range(X_train_c.shape[1]):\n",
    "    X_train_c_mean = X_train_c[:, i]. mean()\n",
    "    X_train_c_std = X_train_c[:, i].std()\n",
    "    X_train_c[:, i] = (X_train_c[:,i] - X_train_c_mean) / X_train_c_std\n",
    "    X_test_c[:,i] = (X_test_c[:,i] - X_train_c_mean) / X_train_c_std\n",
    "    X_val_c[:, i] = (X_val_c[:,i] - X_train_c_mean) / X_train_c_std\n",
    "\n",
    "print(\"X_train_c shape:\", X_train_c.shape)\n",
    "print(\"X_val_c shape:\\t\", X_val_c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA for regressor\n",
    "# set PCA value\n",
    "pca = PCA(0.95)\n",
    "\n",
    "# fit PCA training set\n",
    "pca.fit(X_train)\n",
    "\n",
    "# apply transform to training and test set\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "X_val_pca = pca.transform(X_val)\n",
    "\n",
    "print(\"X_train_pca shape:\\t\", X_train_pca.shape)\n",
    "print(\"X_test_pca shape:\\t\", X_test_pca.shape)\n",
    "print(\"X_val_pca shape:\\t\", X_val_pca.shape)\n",
    "print(\"y_train shape:\\t\", y_train.shape)\n",
    "print(\"y_val shape:\\t\", y_val.shape)\n",
    "print(\"y_test shape:\\t\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA for classifier\n",
    "# apply transform to training and test set\n",
    "X_train_c_pca = pca.transform(X_train_c)\n",
    "X_test_c_pca = pca.transform(X_test_c)\n",
    "X_val_c_pca = pca.transform(X_val_c)\n",
    "\n",
    "print(\"X_train_c_pca shape:\\t\", X_train_c_pca.shape)\n",
    "print(\"X_test_c_pca shape:\\t\", X_test_c_pca.shape)\n",
    "print(\"X_val_c_pca shape:\\t\", X_val_c_pca.shape)\n",
    "print(\"y_train_c shape:\", y_train_c.shape)\n",
    "print(\"y_val_c shape:\\t\", y_val_c.shape)\n",
    "print(\"y_test_c shape:\\t\", y_test_c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_var = X_train_c_pca.shape[1]\n",
    "num_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_reg = LinearRegression().fit(X_train_pca, y_train)\n",
    "score_multiple_reg = multiple_reg.score(X_test_pca, y_test)\n",
    "\n",
    "print('score_multiple_reg:', \"%.4f\" % score_multiple_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGRESSOR_COEF_DICT['multi_linear'] = multiple_reg.coef_\n",
    "REGRESSOR_ACCURACY_DICT['multi_linear'] = score_multiple_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing for different max depth\n",
    "rfc = dict()\n",
    "for i in range (1, 15):\n",
    "    clf = RandomForestClassifier(max_depth=i, random_state=0).fit(X_train_c_pca, y_train_c)\n",
    "    y_pred = clf.predict(X_val_c_pca)\n",
    "    score_clf = accuracy_score(y_val_c, y_pred)\n",
    "    rfc[i] = score_clf\n",
    "\n",
    "max_depth = max(rfc, key=rfc.get)\n",
    "print('max depth:', max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose max_depth = 4\n",
    "rf_clf = RandomForestClassifier(max_depth=int(max_depth), random_state=0).fit(X_train_c_pca, y_train_c)\n",
    "score_rf_clf = rf_clf.score(X_test_c_pca, y_test_c)\n",
    "print('score_rf_clf:', \"%.4f\" % score_rf_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFIER_COEF_DICT['random_forest'] = rf_clf.feature_importances_\n",
    "CLASSIFIER_ACCURACY_DICT['random_forest'] = score_rf_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_reg = RandomForestRegressor().fit(X_train_pca, y_train)\n",
    "score_rf_reg = rf_reg.score(X_test_pca, y_test)\n",
    "print('score_rf_reg:', \"%.4f\" % score_rf_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGRESSOR_COEF_DICT['random_forest'] = rf_reg.feature_importances_\n",
    "REGRESSOR_ACCURACY_DICT['random_forest'] = score_rf_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_reg = LogisticRegression(penalty = 'l1', solver='liblinear', random_state=0).fit(X_train_c_pca, y_train_c)\n",
    "score_logistic = logistic_reg.score(X_test_c_pca, y_test_c)\n",
    "print('score_logistic:', \"%.4f\" % score_logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFIER_COEF_DICT['logistic'] = logistic_reg.coef_[0]\n",
    "CLASSIFIER_ACCURACY_DICT['logistic'] = score_logistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient boosting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gra_clf = GradientBoostingClassifier(n_estimators = 200, learning_rate=0.50, max_depth=5, random_state=0).fit(X_train_c_pca, y_train_c)\n",
    "score_gb_clf = gra_clf.score(X_test_c_pca, y_test_c)\n",
    "score_gb_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFIER_COEF_DICT['gradient_boosting'] = gra_clf.feature_importances_\n",
    "CLASSIFIER_ACCURACY_DICT['gradient_boosting'] = score_gb_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient boosting regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gra_reg = GradientBoostingRegressor(random_state=0).fit(X_train_pca, y_train)\n",
    "score_gb_reg = gra_reg.score(X_test_pca, y_test)\n",
    "score_gb_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGRESSOR_COEF_DICT['gradient_boosting'] = gra_reg.feature_importances_\n",
    "REGRESSOR_ACCURACY_DICT['gradient_boosting'] = score_gb_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = XGBClassifier(use_label_encoder=False).fit(X_train_c_pca, y_train_c)\n",
    "score_xgb_clf = xgb_clf.score(X_test_c_pca, y_test_c)\n",
    "score_xgb_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFIER_COEF_DICT['xgboost'] = xgb_clf.feature_importances_\n",
    "CLASSIFIER_ACCURACY_DICT['xgboost'] = score_xgb_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg = XGBRegressor(random_state = 0).fit(X_train_pca, y_train)\n",
    "score_xgb_reg = xgb_reg.score(X_test_pca, y_test)\n",
    "score_xgb_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGRESSOR_COEF_DICT['xgboost'] = xgb_reg.feature_importances_\n",
    "REGRESSOR_ACCURACY_DICT['xgboost'] = score_xgb_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adb_clf = AdaBoostClassifier().fit(X_train_c_pca, y_train_c)\n",
    "score_adb_clf = adb_clf.score(X_test_c_pca, y_test_c)\n",
    "score_adb_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFIER_COEF_DICT['adaboost'] = adb_clf.feature_importances_\n",
    "CLASSIFIER_ACCURACY_DICT['adaboost'] = score_adb_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adb_reg = AdaBoostRegressor().fit(X_train_pca, y_train)\n",
    "score_adb_reg = adb_reg.score(X_test_pca, y_test)\n",
    "score_adb_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGRESSOR_COEF_DICT['adaboost'] = adb_reg.feature_importances_\n",
    "REGRESSOR_ACCURACY_DICT['adaboost'] = score_adb_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support vector classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different kernels\n",
    "kernels = ('linear', 'poly', 'rbf')\n",
    "\n",
    "for k in kernels:\n",
    "    svm_clf = SVC(kernel=k).fit(X_train_c_pca, y_train_c)\n",
    "    y_pred = svm_clf.predict(X_test_c_pca)\n",
    "    vars()[f'score_svc_{k}']= accuracy_score(y_test_c, y_pred)\n",
    "    \n",
    "    if k == 'linear':\n",
    "        CLASSIFIER_COEF_DICT['svc_linear'] = svm_clf.coef_[0]\n",
    "    \n",
    "print(score_svc_linear)\n",
    "print(score_svc_poly)\n",
    "print(score_svc_rbf)\n",
    "\n",
    "CLASSIFIER_ACCURACY_DICT['svc_linear'] = score_svc_linear\n",
    "CLASSIFIER_ACCURACY_DICT['svc_poly'] = score_svc_poly\n",
    "CLASSIFIER_ACCURACY_DICT['svc_rbf'] = score_svc_rbf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_clf = GaussianNB().fit(X_train_c_pca, y_train_c)\n",
    "score_gnb = gnb_clf.score(X_test_c_pca, y_test_c)\n",
    "print(score_gnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFIER_ACCURACY_DICT['GaussianNB'] = score_gnb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuro networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(10, input_dim=num_var, activation='relu'))\n",
    "model.add(keras.layers.Dense(5, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train_c_pca, y_train_c, epochs=50, validation_data=(X_val_c_pca, y_val_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, score_neuro = model.evaluate(X_test_c_pca, y_test_c)\n",
    "print(score_neuro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFIER_ACCURACY_DICT['neuro'] = score_neuro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_df = pd.DataFrame.from_dict(REGRESSOR_ACCURACY_DICT , orient='index', columns=['Score'])\n",
    "reg_df.index.name = 'Regression models'\n",
    "#reg_df.sort_values(by=['Score'], ascending=False)\n",
    "reg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_df = pd.DataFrame.from_dict(CLASSIFIER_ACCURACY_DICT, orient='index',columns=['Score'])\n",
    "clf_df.index.name = 'Classifier models'\n",
    "#clf_df.sort_values(by=['Score'], ascending=False)\n",
    "clf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_coef_df = pd.DataFrame.from_dict(REGRESSOR_COEF_DICT, orient='index')\n",
    "reg_coef_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_coef_df = pd.DataFrame.from_dict(CLASSIFIER_COEF_DICT, orient='index')\n",
    "clf_coef_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export\n",
    "book = load_workbook('Results.xlsx')\n",
    "writer = pd.ExcelWriter('Results.xlsx', engine='openpyxl')\n",
    "writer.book = book\n",
    "\n",
    "writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "reg_df.to_excel(writer, sheet_name='%s reg score' % sheetname)\n",
    "clf_df.to_excel(writer, sheet_name='%s clf score' % sheetname)\n",
    "reg_coef_df.to_excel(writer, sheet_name='%s reg coef' % sheetname)\n",
    "clf_coef_df.to_excel(writer, sheet_name='%s clf coef' % sheetname)\n",
    "\n",
    "writer.save()\n",
    "#reg_df.to_csv('reg_df.csv')\n",
    "#clf_df.to_csv('clf_df.csv')\n",
    "#reg_coef_df.to_csv('reg_coef_df.csv')\n",
    "#clf_coef_df.to_csv('clf_coef_df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
